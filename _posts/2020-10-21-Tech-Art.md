---
published: false
---
# Tech Art
#blog


Initially I wasn’t very keen on this fortnight’s theme of “replication” for the Tech Art Challenge. It was a little bit too open, I had an idea of copying the “swimming through swamp water effect” from The Last of Us 2, but then, at work, we were discussing games with different effects and Perception came up.

Perception is a survival horror game, made by The Deep End Games in 2017. And the main mechanic of it is that the heroine, Cassie, is blind. She can only see by echolocation, so she taps her cane and can see where a clock chimes and pipes rumble.

The view the player has is a very ghostly blue vision, adding to the eerie atmosphere of this New England mansion.

I haven’t actually played Perception, but from watching some videos of the gameplay I had a pretty good idea of how this was done, or rather how I would do it. I had made post processing shaders before that use depth, or distance from a set point to transition between two camera views, so that’s where I started.

Part One: The Post Processing Shader

I used this tutorial as a basis: [Shaders Case Study - No Man’s Sky: Topographic Scanner - YouTube](https://www.youtube.com/watch?v=OKoNp2RqE9A). In which a scanner moves out from a specific point. The placement of the scan line is based on the “scan distance” from the set point, which gradually increases.

But I don’t need the whole of this shader and script. My properties look like this:

~~~
    Properties
    {
        _Black(“Black”, Color) = (1, 1, 1, 0)
        _Layers(“Layers”, float) = 0
    }
~~~

Black is the dark colour, it shouldn’t be completely #000000, but pretty dark. I went for a rather dark blue. And the layers control how dense the effect is.

Next is where the properties are declared:
~~~
            sampler2D _MainTex, _CameraDepthTexture;

            float4 _WorldSpaceScannerPos[100];
            float _ScanDistanceArr[100];
            int _ArrayLength;

            float _Black, _Layers;
~~~

We need a lot less than in the original, but we are adding two arrays and an integer to track the array. See the tutorial uses one point of origin for the scan, only one point to take information from and we need more. Maybe 100 is overkill.

Now the fragment shader:


~~~
            half4 frag (VertOut i) : SV_Target
            {

                half4 col = tex2D(_MainTex, i.uv);

                float rawDepth = DecodeFloatRG(tex2D(_CameraDepthTexture, i.uv_depth));
                float linearDepth = Linear01Depth(rawDepth);
                float4 wsDir = linearDepth * i.interpolatedRay;
                float3 wsPos = _WorldSpaceCameraPos + wsDir;
                half4 scannerCol = _Black;

                float mask = 0;

                for(int I=0; I<_ArrayLength; I++)
                {
                    float3 dist = distance(wsPos, _WorldSpaceScannerPos[I]);
                    float3 sphere = 1 - saturate(dist/_ScanDistanceArr[i]);
                    sphere = saturate(sphere*_Layers);

                    mask += sphere.r;
                }

                mask = saturate(mask);

                return lerp(scannerCol, col, mask);
            }

~~~

The top chunk of this is pretty much the same, but we set scannerCol as the dark colour we selected earlier. 

The script inside the for loop returns what is essentially a blob around each point in the _WorldSpaceScannerPos and adds it to my mask.  Note that this array doesn’t use the actual length of either array, rather the ArrayLength int.

I might overuse saturate, but it ensures the value stays between 0 and 1, and that we don’t get any crazy oversaturated bright parts.

Then at end we return a lerp between the camera feed and the dark colour, based on the mask we just made.

Part Two: The Script
